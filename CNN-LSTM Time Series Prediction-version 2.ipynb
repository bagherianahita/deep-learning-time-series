{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAGyqIlRpBzJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6-pboyGo63v"
      },
      "outputs": [],
      "source": [
        "data preprocessing steps : data cleaning and signal filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI6LMClOoY1A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "print(\"---Simulating Raw Data---\")\n",
        "np.random.seed(42)\n",
        "depth = np.arange(0, 500, 0.1)\n",
        "# Create a noisy signal for Rate of Penetration (ROP)\n",
        "rop_signal = np.sin(depth / 50) * 10 + 30\n",
        "noise = np.random.normal(0, 3, rop_signal.shape)\n",
        "noisy_rop = rop_signal + noise\n",
        "\n",
        "# Introduce missing values and outliers for cleaning\n",
        "noisy_rop[100:110] = np.nan # Missing values\n",
        "noisy_rop[250] = 100 # Outlier\n",
        "noisy_rop[400] = -50 # Another outlier\n",
        "\n",
        "df = pd.DataFrame({'TVD': depth, 'ROP': noisy_rop})\n",
        "\n",
        "# --- 2. Data Cleaning ---\n",
        "print(\"\\n---Cleaning Data---\")\n",
        "# Fill missing values using linear interpolation\n",
        "df['ROP_cleaned'] = df['ROP'].interpolate(method='linear')\n",
        "print(\"Missing values handled.\")\n",
        "\n",
        "# Remove outliers using the Interquartile Range (IQR) method\n",
        "Q1 = df['ROP_cleaned'].quantile(0.25)\n",
        "Q3 = df['ROP_cleaned'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "df['ROP_cleaned'] = np.where(df['ROP_cleaned'] > upper_bound, upper_bound, df['ROP_cleaned'])\n",
        "df['ROP_cleaned'] = np.where(df['ROP_cleaned'] < lower_bound, lower_bound, df['ROP_cleaned'])\n",
        "print(\"Outliers removed.\")\n",
        "\n",
        "# --- 3. Signal Processing Filters ---\n",
        "print(\"\\n---Applying Signal Filters---\")\n",
        "# Rolling Mean Filter\n",
        "window_size_mean = 20\n",
        "df['ROP_rolling_mean'] = df['ROP_cleaned'].rolling(window=window_size_mean, center=True).mean()\n",
        "print(f\"Rolling Mean applied with window size: {window_size_mean}.\")\n",
        "\n",
        "# Low-pass Filter\n",
        "def butter_lowpass_filter(data, cutoff, fs, order):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "fs = 1000.0 # Sample rate, Hz\n",
        "cutoff = 50.0 # Desired cutoff frequency of the filter, Hz\n",
        "order = 2 # The order of the filter\n",
        "df['ROP_lowpass'] = butter_lowpass_filter(df['ROP_cleaned'], cutoff, fs, order)\n",
        "print(f\"Low-pass filter applied with cutoff frequency: {cutoff}.\")\n",
        "\n",
        "print(\"\\nData processing complete. You can now visualize or use the filtered data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2socOfrpNUT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# --- 1. Simulate a Labeled Dataset ---\n",
        " # features = ['TVD', 'SWOB', 'STOR', 'ROP', 'GR', 'RPM', 'HoleSize', 'TFLO']\n",
        "# target = 'DTCO' (Sonic Log)\n",
        "print(\"---Simulating Labeled Data---\")\n",
        "np.random.seed(42)\n",
        "data_size = 5000\n",
        "df_ml = pd.DataFrame({\n",
        "    'TVD': np.linspace(0, 500, data_size),\n",
        "    'SWOB': np.random.rand(data_size) * 100,\n",
        "    'ROP': np.random.rand(data_size) * 50,\n",
        "    'GR': np.random.rand(data_size) * 120,\n",
        "    # A dummy target variable (Sonic Log) with some noise\n",
        "    'DTCO': (np.sin(np.linspace(0, 20, data_size)) * 50 + 100) + np.random.normal(0, 5, data_size)\n",
        "})\n",
        "features = ['TVD', 'SWOB', 'ROP', 'GR']\n",
        "target = 'DTCO'\n",
        "\n",
        "# --- 2. Data Splitting and Scaling ---\n",
        "X = df_ml[features]\n",
        "y = df_ml[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# --- 3. Model Training and Evaluation ---\n",
        "print(\"\\n---Training and Evaluating Models---\")\n",
        "\n",
        "# XGBoost Regressor\n",
        "print(\"\\nTraining XGBoost...\")\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test_scaled)\n",
        "print(f\"XGBoost R-squared: {r2_score(y_test, xgb_pred):.4f}\")\n",
        "\n",
        "# AdaBoost Regressor\n",
        "print(\"\\nTraining AdaBoost...\")\n",
        "adaboost_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
        "adaboost_model.fit(X_train_scaled, y_train)\n",
        "adaboost_pred = adaboost_model.predict(X_test_scaled)\n",
        "print(f\"AdaBoost R-squared: {r2_score(y_test, adaboost_pred):.4f}\")\n",
        "\n",
        "# Artificial Neural Network (ANN)\n",
        "print(\"\\nTraining ANN...\")\n",
        "ann_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
        "ann_model.fit(X_train_scaled, y_train)\n",
        "ann_pred = ann_model.predict(X_test_scaled)\n",
        "print(f\"ANN R-squared: {r2_score(y_test, ann_pred):.4f}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx2euoTipUpm"
      },
      "source": [
        "Hybrid CNN-LSTM Model for Time Series Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUidsNdepY-Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# --- 1. Simulate Sequential Data ---\n",
        "print(\"---Simulating Time-Series Data---\")\n",
        "np.random.seed(42)\n",
        "data_size = 5000\n",
        "depth = np.linspace(0, 500, data_size)\n",
        "# Simulate sequential features\n",
        "features_ts = pd.DataFrame({\n",
        "    'ROP': np.sin(depth / 10) * 10 + np.random.normal(0, 1, data_size),\n",
        "    'GR': np.cos(depth / 15) * 20 + np.random.normal(0, 2, data_size),\n",
        "    'TFLO': np.sin(depth / 12) * 5 + np.random.normal(0, 0.5, data_size)\n",
        "})\n",
        "# Simulate the sequential target (Sonic Log)\n",
        "dtco_ts = (np.sin(depth / 10) * 50 + 100) + np.random.normal(0, 5, data_size)\n",
        "\n",
        "# --- 2. Preprocessing for CNN-LSTM ---\n",
        "print(\"\\n---Preprocessing Data for CNN-LSTM---\")\n",
        "# Normalize data\n",
        "scaler = MinMaxScaler()\n",
        "features_scaled = scaler.fit_transform(features_ts)\n",
        "dtco_scaled = scaler.fit_transform(dtco_ts.values.reshape(-1, 1))\n",
        "\n",
        "# Create sequences for the model\n",
        "def create_sequences(features, target, time_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(features) - time_steps):\n",
        "        X.append(features[i:(i + time_steps)])\n",
        "        y.append(target[i + time_steps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_steps = 10\n",
        "X_seq, y_seq = create_sequences(features_scaled, dtco_scaled, time_steps)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.15, random_state=42, shuffle=False)\n",
        "# Note: Shuffle is set to False to maintain the sequential nature of the data\n",
        "\n",
        "# --- 3. Build and Train Hybrid CNN-LSTM Model ---\n",
        "print(\"\\n---Building and Training Hybrid CNN-LSTM Model---\")\n",
        "model = Sequential()\n",
        "# CNN layer to extract features\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "# LSTM layer to learn sequence patterns\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# Output layer\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "# --- 4. Evaluate Model ---\n",
        "print(\"\\n---Evaluating Model---\")\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "# Inverse scale the predictions to original values\n",
        "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
        "y_test_orig = scaler.inverse_transform(y_test)\n",
        "print(f\"Hybrid CNN-LSTM R-squared: {r2_score(y_test_orig, y_pred):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}